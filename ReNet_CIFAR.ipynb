{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "ReNet_CIFAR.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRkSnjfkmDYa"
      },
      "source": [
        "!pip install einops\n",
        "!pip install kornia\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from contextlib import contextmanager\n",
        "import torchvision\n",
        "import torch\n",
        "from torchvision.datasets import MNIST,CIFAR10\n",
        "import matplotlib.pyplot as plt\n",
        "from six import add_metaclass\n",
        "from torch.nn import init\n",
        "import torch.optim as optim\n",
        "import os\n",
        "from torch.utils.data import DataLoader,random_split\n",
        "from torchvision.utils import save_image\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision import datasets, transforms\n",
        "from contextlib import contextmanager\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize, RandomCrop\n",
        "from six import add_metaclass\n",
        "from torch.optim import Adam, lr_scheduler\n",
        "\n",
        "from kornia.augmentation import RandomCrop, Normalize\n",
        "from argparse import ArgumentParser\n",
        "import errno\n",
        "from einops import rearrange"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4esx7AxmDY_"
      },
      "source": [
        "def weights_init(m):\n",
        "    # Code taken from https://discuss.pytorch.org/t/initializing-rnn-gru-and-lstm-correctly/23605/8\n",
        "    parameters = m.state_dict()\n",
        "    for each_key in parameters.keys():\n",
        "        print(f'Init-{each_key}')\n",
        "        if 'weight_ih' in each_key:\n",
        "            nn.init.orthogonal_(parameters[each_key])\n",
        "        elif 'weight_hh' in each_key:\n",
        "            nn.init.orthogonal_(parameters[each_key])\n",
        "        elif 'bias' in each_key:\n",
        "            nn.init.constant_(parameters[each_key], val=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXba2WH8mDZD"
      },
      "source": [
        "class ReNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, kernel_size=(2, 2), rnn='GRU', depth=(1,1)):\n",
        "        super(ReNet, self).__init__()\n",
        "        if rnn == 'GRU':\n",
        "            rnn = nn.GRU\n",
        "        elif rnn == 'LSTM':\n",
        "            rnn = nn.LSTM\n",
        "        \n",
        "        self.lstm_h = rnn(input_size, hidden_size, bias=False, num_layers=depth[0], bidirectional=True)\n",
        "        self.lstm_v = rnn(hidden_size * 2, hidden_size, bias=False, num_layers=depth[1], bidirectional=True)\n",
        "\n",
        "        if isinstance(kernel_size, int):\n",
        "            self.kernel_size = (kernel_size, kernel_size)\n",
        "        else:\n",
        "            self.kernel_size = kernel_size\n",
        "        \n",
        "        self.lstm_h.apply(weights_init)\n",
        "        self.lstm_v.apply(weights_init)\n",
        "\n",
        "    def forward(self, x):\n",
        "        k_w, k_h = self.kernel_size\n",
        "        b, c, h, w = x.size()\n",
        "        assert h % k_h == 0 and w % k_w == 0, 'input size does not match with kernel size'\n",
        "        x = rearrange(x, 'b c (h1 h2) (w1 w2) -> h1 (b w1) (c h2 w2)', w2=k_w, h2=k_h)\n",
        "        x, _ = self.lstm_h(x)\n",
        "        x = rearrange(x, 'h1 (b w1) (c h2 w2) -> w1 (b h1) (c h2 w2)', b=b, w2=k_w, h2=k_h)\n",
        "        x, _ = self.lstm_v(x)\n",
        "        x = rearrange(x, 'w1 (b h1) (c h2 w2) -> b (c h2 w2) h1 w1', b=b, w2=k_w, h2=k_h)\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEtECJ0ImDZI"
      },
      "source": [
        "renet = nn.Sequential(\n",
        "    ReNet(2 * 2 * 3, 128, kernel_size=(2, 2)), \n",
        "    ReNet(2 * 2 * 256, 128, kernel_size=(2, 2)),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(256 * 8 * 8, 4096),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(4096, 10),\n",
        ")\n",
        "device = torch.device('cuda:0')\n",
        "renet = renet.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELi647rNmDZR"
      },
      "source": [
        "transform_list = [\n",
        "      transforms.Pad(padding=4, padding_mode='reflect'),\n",
        "      transforms.RandomCrop(32),\n",
        "      transforms.RandomHorizontalFlip(),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "]\n",
        "\n",
        "CIFAR_dataset_train = CIFAR10('./data',train=True,download=True,transform=transforms.Compose(transform_list))\n",
        "CIFAR_dataset_test = CIFAR10('./data',train=False,download=True,transform=transforms.Compose(transform_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buAI8-PSmDZ0"
      },
      "source": [
        "cifar_train_loader = DataLoader(CIFAR_dataset_train,shuffle=True,batch_size=128,pin_memory=True)\n",
        "cifar_test_loader = DataLoader(CIFAR_dataset_test,shuffle=True,batch_size=128,pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w50zi7PVmDZ8"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fji9BV0fp5ca"
      },
      "source": [
        "num_epochs = 20\n",
        "learning_rate = 0.01\n",
        "optimizer = torch.optim.SGD(renet.parameters(), lr=learning_rate)  \n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOr6YAD1mDZ_"
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "    for images,labels in cifar_train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        \n",
        "        outputs = renet(images)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    correct = 0\n",
        "    total = 0\n",
        "    accuracy = 0\n",
        "    for images, labels in cifar_test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "            \n",
        "        outputs = renet(images)\n",
        "            \n",
        "        predictions = torch.argmax(outputs, dim=1)\n",
        "        correct += (predictions == labels).sum()\n",
        "            \n",
        "        total += len(labels)\n",
        "            \n",
        "        accuracy = correct * 100 / total\n",
        "    print(\"Epoch: {}, Test Accuracy: {}%\".format(epoch, accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}