{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "ReNet_CIFAR.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRkSnjfkmDYa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3edb58f-cb5a-4134-aa4d-b3f3dec92a41"
      },
      "source": [
        "!pip install einops\n",
        "!pip install kornia\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from contextlib import contextmanager\n",
        "import torchvision\n",
        "import torch\n",
        "from torchvision.datasets import MNIST,CIFAR10\n",
        "import matplotlib.pyplot as plt\n",
        "from six import add_metaclass\n",
        "from torch.nn import init\n",
        "import torch.optim as optim\n",
        "import os\n",
        "from torch.utils.data import DataLoader,random_split\n",
        "from torchvision.utils import save_image\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision import datasets, transforms\n",
        "from contextlib import contextmanager\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize, RandomCrop\n",
        "from six import add_metaclass\n",
        "from torch.optim import Adam, lr_scheduler\n",
        "\n",
        "from kornia.augmentation import RandomCrop, Normalize\n",
        "from argparse import ArgumentParser\n",
        "import errno\n",
        "from einops import rearrange"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: kornia in /usr/local/lib/python3.6/dist-packages (0.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from kornia) (1.19.5)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from kornia) (1.7.0+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->kornia) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->kornia) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->kornia) (0.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4esx7AxmDY_"
      },
      "source": [
        "def weights_init(m):\n",
        "    # Code taken from https://discuss.pytorch.org/t/initializing-rnn-gru-and-lstm-correctly/23605/8\n",
        "    parameters = m.state_dict()\n",
        "    for each_key in parameters.keys():\n",
        "        print(f'Init-{each_key}')\n",
        "        if 'weight_ih' in each_key:\n",
        "            nn.init.orthogonal_(parameters[each_key])\n",
        "        elif 'weight_hh' in each_key:\n",
        "            nn.init.orthogonal_(parameters[each_key])\n",
        "        elif 'bias' in each_key:\n",
        "            nn.init.constant_(parameters[each_key], val=0)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXba2WH8mDZD"
      },
      "source": [
        "class ReNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, kernel_size=(2, 2), rnn='GRU', depth=(1,1)):\n",
        "        super(ReNet, self).__init__()\n",
        "        if rnn == 'GRU':\n",
        "            rnn = nn.GRU\n",
        "        elif rnn == 'LSTM':\n",
        "            rnn = nn.LSTM\n",
        "        \n",
        "        self.lstm_h = rnn(input_size, hidden_size, bias=False, num_layers=depth[0], bidirectional=True)\n",
        "        self.lstm_v = rnn(hidden_size * 2, hidden_size, bias=False, num_layers=depth[1], bidirectional=True)\n",
        "\n",
        "        if isinstance(kernel_size, int):\n",
        "            self.kernel_size = (kernel_size, kernel_size)\n",
        "        else:\n",
        "            self.kernel_size = kernel_size\n",
        "        \n",
        "        self.lstm_h.apply(weights_init)\n",
        "        self.lstm_v.apply(weights_init)\n",
        "\n",
        "    def forward(self, x):\n",
        "        k_w, k_h = self.kernel_size\n",
        "        b, c, h, w = x.size()\n",
        "        assert h % k_h == 0 and w % k_w == 0, 'input size does not match with kernel size'\n",
        "        x = rearrange(x, 'b c (h1 h2) (w1 w2) -> h1 (b w1) (c h2 w2)', w2=k_w, h2=k_h)\n",
        "        x, _ = self.lstm_h(x)\n",
        "        x = rearrange(x, 'h1 (b w1) (c h2 w2) -> w1 (b h1) (c h2 w2)', b=b, w2=k_w, h2=k_h)\n",
        "        x, _ = self.lstm_v(x)\n",
        "        x = rearrange(x, 'w1 (b h1) (c h2 w2) -> b (c h2 w2) h1 w1', b=b, w2=k_w, h2=k_h)\n",
        "        return x\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEtECJ0ImDZI",
        "outputId": "437fd7dc-ef46-4804-9158-dede3ef9326f"
      },
      "source": [
        "renet = nn.Sequential(\n",
        "    ReNet(2 * 2 * 3, 128, kernel_size=(2, 2)), \n",
        "    ReNet(2 * 2 * 256, 128, kernel_size=(2, 2)),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(256 * 8 * 8, 4096),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(4096, 10),\n",
        ")\n",
        "device = torch.device('cuda:0')\n",
        "renet = renet.to(device)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Init-weight_ih_l0\n",
            "Init-weight_hh_l0\n",
            "Init-weight_ih_l0_reverse\n",
            "Init-weight_hh_l0_reverse\n",
            "Init-weight_ih_l0\n",
            "Init-weight_hh_l0\n",
            "Init-weight_ih_l0_reverse\n",
            "Init-weight_hh_l0_reverse\n",
            "Init-weight_ih_l0\n",
            "Init-weight_hh_l0\n",
            "Init-weight_ih_l0_reverse\n",
            "Init-weight_hh_l0_reverse\n",
            "Init-weight_ih_l0\n",
            "Init-weight_hh_l0\n",
            "Init-weight_ih_l0_reverse\n",
            "Init-weight_hh_l0_reverse\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELi647rNmDZR",
        "outputId": "a029bd4e-6b50-4611-9b10-67d597b5f857"
      },
      "source": [
        "transform_list = [\n",
        "      transforms.Pad(padding=4, padding_mode='reflect'),\n",
        "      transforms.RandomCrop(32),\n",
        "      transforms.RandomHorizontalFlip(),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "]\n",
        "\n",
        "CIFAR_dataset_train = CIFAR10('./data',train=True,download=True,transform=transforms.Compose(transform_list))\n",
        "CIFAR_dataset_test = CIFAR10('./data',train=False,download=True,transform=transforms.Compose(transform_list))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buAI8-PSmDZ0"
      },
      "source": [
        "cifar_train_loader = DataLoader(CIFAR_dataset_train,shuffle=True,batch_size=128,pin_memory=True)\n",
        "cifar_test_loader = DataLoader(CIFAR_dataset_test,shuffle=True,batch_size=128,pin_memory=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w50zi7PVmDZ8"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fji9BV0fp5ca"
      },
      "source": [
        "num_epochs = 20\n",
        "learning_rate = 0.01\n",
        "optimizer = torch.optim.SGD(renet.parameters(), lr=learning_rate)  \n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOr6YAD1mDZ_",
        "outputId": "01a21e5f-c6e5-4ab9-81ad-777bed9c2bea"
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "    for images,labels in cifar_train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        \n",
        "        outputs = renet(images)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    correct = 0\n",
        "    total = 0\n",
        "    accuracy = 0\n",
        "    for images, labels in cifar_test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "            \n",
        "        outputs = renet(images)\n",
        "            \n",
        "        predictions = torch.argmax(outputs, dim=1)\n",
        "        correct += (predictions == labels).sum()\n",
        "            \n",
        "        total += len(labels)\n",
        "            \n",
        "        accuracy = correct * 100 // total\n",
        "    print(\"Epoch: {}, Test Accuracy: {}%\".format(epoch, accuracy))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Test Accuracy: 27%\n",
            "Epoch: 1, Test Accuracy: 32%\n",
            "Epoch: 2, Test Accuracy: 35%\n",
            "Epoch: 3, Test Accuracy: 37%\n",
            "Epoch: 4, Test Accuracy: 38%\n",
            "Epoch: 5, Test Accuracy: 39%\n",
            "Epoch: 6, Test Accuracy: 40%\n",
            "Epoch: 7, Test Accuracy: 41%\n",
            "Epoch: 8, Test Accuracy: 42%\n",
            "Epoch: 9, Test Accuracy: 42%\n",
            "Epoch: 10, Test Accuracy: 43%\n",
            "Epoch: 11, Test Accuracy: 44%\n",
            "Epoch: 12, Test Accuracy: 45%\n",
            "Epoch: 13, Test Accuracy: 45%\n",
            "Epoch: 14, Test Accuracy: 46%\n",
            "Epoch: 15, Test Accuracy: 46%\n",
            "Epoch: 16, Test Accuracy: 47%\n",
            "Epoch: 17, Test Accuracy: 48%\n",
            "Epoch: 18, Test Accuracy: 48%\n",
            "Epoch: 19, Test Accuracy: 48%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}