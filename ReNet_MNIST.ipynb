{"cells":[{"metadata":{"id":"oRkSnjfkmDYa","trusted":true},"cell_type":"code","source":"!pip install einops\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom contextlib import contextmanager\nimport torchvision\nimport torch\nfrom torchvision.datasets import MNIST,CIFAR10\nimport matplotlib.pyplot as plt\nfrom six import add_metaclass\nfrom torch.nn import init\nimport torch.optim as optim\nimport os\nfrom torch.utils.data import DataLoader,random_split\nfrom torchvision.utils import save_image\nimport numpy as np\nfrom PIL import Image\nfrom torchvision import datasets, transforms\nfrom contextlib import contextmanager\nfrom torchvision.transforms import Compose, ToTensor, Normalize, RandomCrop\nfrom six import add_metaclass\nfrom torch.optim import Adam, lr_scheduler\n\nfrom kornia.augmentation import RandomCrop, Normalize\nfrom argparse import ArgumentParser\nimport errno\nfrom einops import rearrange","execution_count":1,"outputs":[{"output_type":"stream","text":"Collecting einops\n  Downloading einops-0.3.0-py2.py3-none-any.whl (25 kB)\nInstalling collected packages: einops\nSuccessfully installed einops-0.3.0\n\u001b[33mWARNING: You are using pip version 20.3.1; however, version 20.3.3 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","name":"stdout"}]},{"metadata":{"id":"O4esx7AxmDY_","trusted":true},"cell_type":"code","source":"def weights_init(m):\n    # Code taken from https://discuss.pytorch.org/t/initializing-rnn-gru-and-lstm-correctly/23605/8\n    parameters = m.state_dict()\n    for each_key in parameters.keys():\n        print(f'Init-{each_key}')\n        if 'weight_ih' in each_key:\n            nn.init.orthogonal_(parameters[each_key])\n        elif 'weight_hh' in each_key:\n            nn.init.orthogonal_(parameters[each_key])\n        elif 'bias' in each_key:\n            nn.init.constant_(parameters[each_key], val=0)","execution_count":2,"outputs":[]},{"metadata":{"id":"PXba2WH8mDZD","trusted":true},"cell_type":"code","source":"class ReNet(nn.Module):\n    def __init__(self, input_size, hidden_size, kernel_size=(4, 4), rnn='LSTM', depth=(1,1)):\n        super(ReNet, self).__init__()\n        if rnn == 'GRU':\n            rnn = nn.GRU\n        elif rnn == 'LSTM':\n            rnn = nn.LSTM\n        \n        self.lstm_h = rnn(input_size, hidden_size, bias=False, num_layers=depth[0], bidirectional=True)\n        self.lstm_v = rnn(hidden_size * 2, hidden_size, bias=False, num_layers=depth[1], bidirectional=True)\n\n        if isinstance(kernel_size, int):\n            self.kernel_size = (kernel_size, kernel_size)\n        else:\n            self.kernel_size = kernel_size\n        \n        self.lstm_h.apply(weights_init)\n        self.lstm_v.apply(weights_init)\n\n    def forward(self, x):\n        k_w, k_h = self.kernel_size \n        b, c, h, w = x.size()\n        \n        assert h % k_h == 0 and w % k_w == 0, 'input size does not match with kernel size'\n        x = rearrange(x, 'b c (h1 h2) (w1 w2) -> h1 (b w1) (c h2 w2)', w2=k_w, h2=k_h)\n        x, _ = self.lstm_h(x)\n        x = rearrange(x, 'h1 (b w1) (c h2 w2) -> w1 (b h1) (c h2 w2)', b=b, w2=k_w, h2=k_h)\n        x, _ = self.lstm_v(x)\n        x = rearrange(x, 'w1 (b h1) (c h2 w2) -> b (c h2 w2) h1 w1', b=b, w2=k_w, h2=k_h)\n        return x\n        ","execution_count":3,"outputs":[]},{"metadata":{"id":"pEtECJ0ImDZI","outputId":"88e808c5-a82f-4f72-d1e4-a5b492faf1c7","trusted":true},"cell_type":"code","source":"renet = nn.Sequential(\n    ReNet(4, 128, kernel_size=(2,2)), \n    ReNet(1024,128,kernel_size=(2,2)),\n    nn.Flatten(),\n    nn.Linear(256 * 7 * 7, 4096),\n    nn.ReLU(),\n    nn.Linear(4096, 10),\n)\n\n\ndevice = torch.device('cuda:0')\nrenet = renet.to(device)","execution_count":4,"outputs":[{"output_type":"stream","text":"Init-weight_ih_l0\nInit-weight_hh_l0\nInit-weight_ih_l0_reverse\nInit-weight_hh_l0_reverse\nInit-weight_ih_l0\nInit-weight_hh_l0\nInit-weight_ih_l0_reverse\nInit-weight_hh_l0_reverse\nInit-weight_ih_l0\nInit-weight_hh_l0\nInit-weight_ih_l0_reverse\nInit-weight_hh_l0_reverse\nInit-weight_ih_l0\nInit-weight_hh_l0\nInit-weight_ih_l0_reverse\nInit-weight_hh_l0_reverse\n","name":"stdout"}]},{"metadata":{"id":"ELi647rNmDZR","trusted":true},"cell_type":"code","source":"\ntransform_list = [\n    transforms.ToTensor(),\n    transforms.Normalize((0.1307,), (0.3081,))\n]\n'''\ntorchvision.transforms.Compose([\n                               torchvision.transforms.ToTensor(),\n                            transforms.CenterCrop((448,448)),\n                               torchvision.transforms.Normalize(\n                                 (0.1307,), (0.3081,))\n])\n'''\nmnist_train_data = datasets.MNIST(root='data', train=True,download=True, transform=transforms.Compose(transform_list))\nmnist_test_data = datasets.MNIST(root='data', train=False,download=True, transform=transforms.Compose(transform_list))","execution_count":5,"outputs":[{"output_type":"stream","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c76e99c4cc274f47bd563da915deaa61"}},"metadata":{}},{"output_type":"stream","text":"Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36342ea62ab84faa9c85937a810805d1"}},"metadata":{}},{"output_type":"stream","text":"Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04db9d3c8b8d43f9b78c6a8ed7bdbd83"}},"metadata":{}},{"output_type":"stream","text":"Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc5cac1fcdd349ed9ff4713522d85f02"}},"metadata":{}},{"output_type":"stream","text":"Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\nProcessing...\nDone!\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729138878/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n","name":"stderr"}]},{"metadata":{"id":"buAI8-PSmDZ0","trusted":true},"cell_type":"code","source":"mnist_train_loader = DataLoader(mnist_train_data,shuffle=True,batch_size=1024,pin_memory=True)\nmnist_test_loader = DataLoader(mnist_test_data,shuffle=True,batch_size=1024,pin_memory=True)","execution_count":6,"outputs":[]},{"metadata":{"id":"Fji9BV0fp5ca","trusted":true},"cell_type":"code","source":"num_epochs = 5\nlearning_rate = 0.01\n\noptimizer = torch.optim.SGD(renet.parameters(), lr=learning_rate)  \ncriterion = nn.CrossEntropyLoss()","execution_count":7,"outputs":[]},{"metadata":{"id":"QOr6YAD1mDZ_","trusted":true},"cell_type":"code","source":"for epoch in range(num_epochs):\n    for images,labels in mnist_train_loader:\n        images, labels = images.to(device), labels.to(device)\n        \n        outputs = renet(images)\n\n        optimizer.zero_grad()\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n    \n    correct = 0\n    total = 0\n    accuracy = 0\n    for images, labels in mnist_test_loader:\n        images, labels = images.to(device), labels.to(device)\n            \n        outputs = renet(images)\n            \n        predictions = torch.argmax(outputs, dim=1)\n        correct += (predictions == labels).sum()\n            \n        total += len(labels)\n            \n        accuracy = correct * 100 // total\n    print(\"Epoch: {}, Test Accuracy: {}%\".format(epoch, accuracy))","execution_count":8,"outputs":[{"output_type":"stream","text":"\n\n\n\nEpoch: 0, Test Accuracy: 10%\nEpoch: 1, Test Accuracy: 10%\nEpoch: 2, Test Accuracy: 11%\nEpoch: 3, Test Accuracy: 11%\nEpoch: 4, Test Accuracy: 11%\n","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-e5861ef9f516>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}