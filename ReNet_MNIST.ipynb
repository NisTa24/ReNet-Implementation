{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "ReNet_MNIST.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRkSnjfkmDYa",
        "trusted": true,
        "outputId": "7f7b828d-27ba-40b7-99c9-d45846148242"
      },
      "source": [
        "!pip install einops\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from contextlib import contextmanager\n",
        "import torchvision\n",
        "import torch\n",
        "from torchvision.datasets import MNIST,CIFAR10\n",
        "import matplotlib.pyplot as plt\n",
        "from six import add_metaclass\n",
        "from torch.nn import init\n",
        "import torch.optim as optim\n",
        "import os\n",
        "from torch.utils.data import DataLoader,random_split\n",
        "from torchvision.utils import save_image\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision import datasets, transforms\n",
        "from contextlib import contextmanager\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize, RandomCrop\n",
        "from six import add_metaclass\n",
        "from torch.optim import Adam, lr_scheduler\n",
        "\n",
        "from kornia.augmentation import RandomCrop, Normalize\n",
        "from argparse import ArgumentParser\n",
        "import errno\n",
        "from einops import rearrange"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting einops\n",
            "  Downloading einops-0.3.0-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: einops\n",
            "Successfully installed einops-0.3.0\n",
            "\u001b[33mWARNING: You are using pip version 20.3.1; however, version 20.3.3 is available.\n",
            "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4esx7AxmDY_",
        "trusted": true
      },
      "source": [
        "def weights_init(m):\n",
        "    # Code taken from https://discuss.pytorch.org/t/initializing-rnn-gru-and-lstm-correctly/23605/8\n",
        "    parameters = m.state_dict()\n",
        "    for each_key in parameters.keys():\n",
        "        print(f'Init-{each_key}')\n",
        "        if 'weight_ih' in each_key:\n",
        "            nn.init.orthogonal_(parameters[each_key])\n",
        "        elif 'weight_hh' in each_key:\n",
        "            nn.init.orthogonal_(parameters[each_key])\n",
        "        elif 'bias' in each_key:\n",
        "            nn.init.constant_(parameters[each_key], val=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXba2WH8mDZD",
        "trusted": true
      },
      "source": [
        "class ReNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, kernel_size=(4, 4), rnn='LSTM', depth=(1,1)):\n",
        "        super(ReNet, self).__init__()\n",
        "        if rnn == 'GRU':\n",
        "            rnn = nn.GRU\n",
        "        elif rnn == 'LSTM':\n",
        "            rnn = nn.LSTM\n",
        "        \n",
        "        self.lstm_h = rnn(input_size, hidden_size, bias=False, num_layers=depth[0], bidirectional=True)\n",
        "        self.lstm_v = rnn(hidden_size * 2, hidden_size, bias=False, num_layers=depth[1], bidirectional=True)\n",
        "\n",
        "        if isinstance(kernel_size, int):\n",
        "            self.kernel_size = (kernel_size, kernel_size)\n",
        "        else:\n",
        "            self.kernel_size = kernel_size\n",
        "        \n",
        "        self.lstm_h.apply(weights_init)\n",
        "        self.lstm_v.apply(weights_init)\n",
        "\n",
        "    def forward(self, x):\n",
        "        k_w, k_h = self.kernel_size \n",
        "        b, c, h, w = x.size()\n",
        "        \n",
        "        assert h % k_h == 0 and w % k_w == 0, 'input size does not match with kernel size'\n",
        "        x = rearrange(x, 'b c (h1 h2) (w1 w2) -> h1 (b w1) (c h2 w2)', w2=k_w, h2=k_h)\n",
        "        x, _ = self.lstm_h(x)\n",
        "        x = rearrange(x, 'h1 (b w1) (c h2 w2) -> w1 (b h1) (c h2 w2)', b=b, w2=k_w, h2=k_h)\n",
        "        x, _ = self.lstm_v(x)\n",
        "        x = rearrange(x, 'w1 (b h1) (c h2 w2) -> b (c h2 w2) h1 w1', b=b, w2=k_w, h2=k_h)\n",
        "        return x\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEtECJ0ImDZI",
        "trusted": true,
        "outputId": "88e808c5-a82f-4f72-d1e4-a5b492faf1c7"
      },
      "source": [
        "renet = nn.Sequential(\n",
        "    ReNet(4, 128, kernel_size=(2,2)), \n",
        "    ReNet(1024,128,kernel_size=(2,2)),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(256 * 7 * 7, 4096),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(4096, 10),\n",
        ")\n",
        "\n",
        "\n",
        "device = torch.device('cuda:0')\n",
        "renet = renet.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Init-weight_ih_l0\n",
            "Init-weight_hh_l0\n",
            "Init-weight_ih_l0_reverse\n",
            "Init-weight_hh_l0_reverse\n",
            "Init-weight_ih_l0\n",
            "Init-weight_hh_l0\n",
            "Init-weight_ih_l0_reverse\n",
            "Init-weight_hh_l0_reverse\n",
            "Init-weight_ih_l0\n",
            "Init-weight_hh_l0\n",
            "Init-weight_ih_l0_reverse\n",
            "Init-weight_hh_l0_reverse\n",
            "Init-weight_ih_l0\n",
            "Init-weight_hh_l0\n",
            "Init-weight_ih_l0_reverse\n",
            "Init-weight_hh_l0_reverse\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELi647rNmDZR",
        "trusted": true,
        "outputId": "c7a014c6-e52d-46b8-bcea-28fde02018e8",
        "colab": {
          "referenced_widgets": [
            "c76e99c4cc274f47bd563da915deaa61",
            "36342ea62ab84faa9c85937a810805d1",
            "04db9d3c8b8d43f9b78c6a8ed7bdbd83",
            "cc5cac1fcdd349ed9ff4713522d85f02"
          ]
        }
      },
      "source": [
        "\n",
        "transform_list = [\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "]\n",
        "'''\n",
        "torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                            transforms.CenterCrop((448,448)),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.1307,), (0.3081,))\n",
        "])\n",
        "'''\n",
        "mnist_train_data = datasets.MNIST(root='data', train=True,download=True, transform=transforms.Compose(transform_list))\n",
        "mnist_test_data = datasets.MNIST(root='data', train=False,download=True, transform=transforms.Compose(transform_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c76e99c4cc274f47bd563da915deaa61"
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36342ea62ab84faa9c85937a810805d1"
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "04db9d3c8b8d43f9b78c6a8ed7bdbd83"
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc5cac1fcdd349ed9ff4713522d85f02"
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729138878/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buAI8-PSmDZ0",
        "trusted": true
      },
      "source": [
        "mnist_train_loader = DataLoader(mnist_train_data,shuffle=True,batch_size=1024,pin_memory=True)\n",
        "mnist_test_loader = DataLoader(mnist_test_data,shuffle=True,batch_size=1024,pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fji9BV0fp5ca",
        "trusted": true
      },
      "source": [
        "num_epochs = 5\n",
        "learning_rate = 0.01\n",
        "\n",
        "optimizer = torch.optim.SGD(renet.parameters(), lr=learning_rate)  \n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOr6YAD1mDZ_",
        "trusted": true,
        "outputId": "e21e114e-b666-4bf2-f514-69fe8934d7e9"
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "    for images,labels in mnist_train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        \n",
        "        outputs = renet(images)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    correct = 0\n",
        "    total = 0\n",
        "    accuracy = 0\n",
        "    for images, labels in mnist_test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "            \n",
        "        outputs = renet(images)\n",
        "            \n",
        "        predictions = torch.argmax(outputs, dim=1)\n",
        "        correct += (predictions == labels).sum()\n",
        "            \n",
        "        total += len(labels)\n",
        "            \n",
        "        accuracy = correct * 100 // total\n",
        "    print(\"Epoch: {}, Test Accuracy: {}%\".format(epoch, accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 0, Test Accuracy: 10%\n",
            "Epoch: 1, Test Accuracy: 10%\n",
            "Epoch: 2, Test Accuracy: 11%\n",
            "Epoch: 3, Test Accuracy: 11%\n",
            "Epoch: 4, Test Accuracy: 11%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-e5861ef9f516>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}